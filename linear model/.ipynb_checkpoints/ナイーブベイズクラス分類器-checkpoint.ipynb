{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ナイーブベイズクラス分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰、線形SVCに似たクラス分類器<br>\n",
    "<b>訓練が線形モデルよりもさらに高速</b><br>\n",
    "この速度の大小として汎化性能はロジスティック回帰、線形SVCよりも性能はわずかに劣ることが多い<br>\n",
    "### なぜ訓練が早いのか\n",
    "クラスに対する統計値をここの特徴量ごとに集めてパラメタを学習するから<br>\n",
    "<br>\n",
    "1. scikit-learnには3種類のナイーブベイズクラス分類器が存在する。<br>\n",
    "     1. GaussianNB   → 任意の連続値データを想定\n",
    "     1. BernoulliNB  → 2値データを想定\n",
    "     1. MultinomialNB→ カウントデータを想定<br>\n",
    "カウントデータとは例えば文中に出てくる単語の出現数などの個々の特徴量が何らかの整数カウントを表現しているデータである。<br>\n",
    "BernoulliNB、multinomialNBはほとんどの場合データのクラス分類に用いられる。<br><br>\n",
    "BernoulliNBクラス分類器は個々のクラスに対して、特徴量ごとに非ゼロである場合はカウントする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1]\n",
      " [0 0 0 1]]\n",
      "[[1 0 1 1]\n",
      " [1 0 1 0]]\n",
      "Feature counts\n",
      " {0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}\n"
     ]
    }
   ],
   "source": [
    "#クラスごとに非ゼロの値をカウント\n",
    "X= np.array([[0,1,0,1],\n",
    "             [1,0,1,1],\n",
    "             [0,0,0,1],\n",
    "             [1,0,1,0]])\n",
    "y=np.array([0,1,0,1])\n",
    "\n",
    "counts = {}\n",
    "for label in np.unique(y):\n",
    "    print(X[y==label])\n",
    "    counts[label] = X[y==label].sum(axis=0)\n",
    "print(\"Feature counts\\n {}\".format(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残りの2つのナイーブベイズモデル、MultinomialNBとGaussianNBは計算する統計量が若干異なる。<br>\n",
    "MultinomialNBではクラスごと、個々の特徴量の平均値を考慮に入れる。<br>\n",
    "GaussianNBでは平均値だけでなく標準偏差も格納する<br>\n",
    "予想の際には個々のクラスの統計量とデータポイントが比較され、最もよく適合したクラスが採用される<br>\n",
    "MultinomialNBやBernoulliNBでは線形モデルの場合と同じカタチの予測式となる。<br>\n",
    "ナイーブベイズモデルのcoef_は線形モデルの場合と若干意味が異なる。ナイーブベイズモデルのcoef_はωと同じでない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利点、欠点、パラメタ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultinomialNBとBernoulliNBにはパラメタが1つだけある。<br>\n",
    "<b>モデルの複雑さを制御するalphaである。</b><br>\n",
    "アルゴリズムはすべての特徴量に対して正の値を持つ仮想的なデータポイントがalphaの大きさに応じた量だけ追加されたかのように振る舞う<br>\n",
    "alphaが大きくなるとスムーズになり、モデルの複雑さは減少する。<br>\n",
    "alphaの値がアルゴリズムの性能に致命的な違いをもたらすことはないが、この値を調整することでいくらか精度を上げることができる。<br>\n",
    "GaussianNBは多くの場合、高次元データに用いられるが、他の２つはテキストのような疎なカウントデータに用いられる。<br>\n",
    "一般にMultinomialNBのほうがBernoulliNBよりも若干性能が良いが疎なデータの場合はMultinomialNBのほうが有効<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
